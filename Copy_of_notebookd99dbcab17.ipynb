{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12201222,
          "sourceType": "datasetVersion",
          "datasetId": 7685637
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnobodai/capstone/blob/main/Copy_of_notebookd99dbcab17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Weights & Biases (used for logging training metrics to the web dashboard)\n"
      ],
      "metadata": {
        "id": "EYd_IGlnFwiG"
      }
    },
    {
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "id": "CJ9DaCgmv3rC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67aa5a63-dc2a-43ac-fe3f-a6a334a747fb"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.20.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.30.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Log in to Weights & Biases"
      ],
      "metadata": {
        "id": "GyXWMSD3GBFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoZ1ic1G_pEv",
        "outputId": "a25c6f80-a7c2-4ffd-c3e9-8ffe6dbbcfe4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mj-obodai\u001b[0m (\u001b[33mj-obodai-african-leadership-group\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Import Weights & Biases and its Keras integration for experiment tracking\n"
      ],
      "metadata": {
        "id": "TZzJq3KvGWjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n"
      ],
      "metadata": {
        "id": "PPyTD0G6FGAl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount Google Drive to access/save model files and training artifacts\n"
      ],
      "metadata": {
        "id": "CHvu0eHFGi0j"
      }
    },
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "kyKfThV6v3rE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a8911c-2e94-43db-ab25-37289c9421b8"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load & Preview Data"
      ],
      "metadata": {
        "id": "9anv6Gx0v3rG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to your TSV file\n",
        "file_path = '/content/drive/MyDrive/pretraining/data.tsv'\n",
        "\n",
        "# Load the TSV file\n",
        "df = pd.read_csv(file_path, sep='\\t', names=['English', 'Ga'])\n",
        "\n",
        "# Preview\n",
        "print(\"üîç Sample data:\")\n",
        "print(df.sample(3))\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:06:50.686823Z",
          "iopub.execute_input": "2025-06-20T05:06:50.687591Z",
          "iopub.status.idle": "2025-06-20T05:06:51.277382Z",
          "shell.execute_reply.started": "2025-06-20T05:06:50.687554Z",
          "shell.execute_reply": "2025-06-20T05:06:51.276484Z"
        },
        "id": "-qXXS51jv3rI",
        "outputId": "333fcf74-3120-4a00-fbb6-b8c1ee998cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Sample data:\n",
            "                                                English  \\\n",
            "585   Then Jehovah said to Moses: ‚ÄúStretch out your ...   \n",
            "8530  The One who made me feel secure on my mother‚Äôs...   \n",
            "2551   The people of the region thought of them all ...   \n",
            "\n",
            "                                                     Ga  \n",
            "585   Ni Yehowa k…õ…õ Mose ak…õ: ‚ÄúKp√£ onine mli y…õ ≈ãsh…î...  \n",
            "8530      M…î ni bu mihe be ni mik√£ miny…õ fuf…îi anaa l…õ.  \n",
            "2551   M…õi ni y…î…î kpokpaa l…õ n…î l…õ susu ak…õ Noa k…õ e...  \n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean and Normalize Text"
      ],
      "metadata": {
        "id": "sCo98e_0v3rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase and strip whitespace\n",
        "df['English'] = df['English'].astype(str).str.lower().str.strip()\n",
        "df['Ga'] = df['Ga'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# Add special tokens to Ga side\n",
        "df['Ga'] = df['Ga'].apply(lambda x: 'startseq ' + x + ' endseq')\n",
        "\n",
        "# Confirm changes\n",
        "df.sample(3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:06:51.278904Z",
          "iopub.execute_input": "2025-06-20T05:06:51.279228Z",
          "iopub.status.idle": "2025-06-20T05:06:51.36682Z",
          "shell.execute_reply.started": "2025-06-20T05:06:51.279204Z",
          "shell.execute_reply": "2025-06-20T05:06:51.366008Z"
        },
        "id": "uRSKrymUv3rK",
        "outputId": "82100574-2038-455d-8d96-90f6cf94e988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                English  \\\n",
              "3527  unaware of the unfolding drama bethlehem slept...   \n",
              "8941                   he commanded, and it stood firm.   \n",
              "3925  however, jon πa¬∑than said to saul his father wh...   \n",
              "\n",
              "                                                     Ga  \n",
              "3527  startseq yosef k…õ maria wo am…õbi yesu k…õts…î du...  \n",
              "8941              startseq ef√£ ni ema shi shi≈ã≈ã. endseq  \n",
              "3925  startseq shi yonatan bi ets…õ saul ak…õ m…õni hew...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e4efe31-4fa7-4f34-a6a7-bb054e326b42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Ga</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3527</th>\n",
              "      <td>unaware of the unfolding drama bethlehem slept...</td>\n",
              "      <td>startseq yosef k…õ maria wo am…õbi yesu k…õts…î du...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8941</th>\n",
              "      <td>he commanded, and it stood firm.</td>\n",
              "      <td>startseq ef√£ ni ema shi shi≈ã≈ã. endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925</th>\n",
              "      <td>however, jon πa¬∑than said to saul his father wh...</td>\n",
              "      <td>startseq shi yonatan bi ets…õ saul ak…õ m…õni hew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e4efe31-4fa7-4f34-a6a7-bb054e326b42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e4efe31-4fa7-4f34-a6a7-bb054e326b42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e4efe31-4fa7-4f34-a6a7-bb054e326b42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-795d007d-a6f1-4e46-8ff9-6e69a1e57347\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-795d007d-a6f1-4e46-8ff9-6e69a1e57347')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-795d007d-a6f1-4e46-8ff9-6e69a1e57347 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"unaware of the unfolding drama bethlehem slept as joseph mary and jesus slipped out of the village in the darkness heading southward with the sky beginning to lighten in the east joseph likely wondered what lay ahead how could a lowly carpenter protect his family against forces so powerful? would he always be able to provide for his own? would he manage to persevere in carrying out this heavy assignment that jehovah god had given him to care for and raise this unique child? joseph faced daunting challenges as we consider how he rose to meet each one we will see why fathers today\\u200b\\u2014and all of us\\u2014\\u200bneed to imitate the faith of joseph\",\n          \"he commanded, and it stood firm.\",\n          \"however, jon\\u02b9a\\u00b7than said to saul his father why should he be put to death? what has he done?  at that saul hurled the spear at him to strike him, so jon\\u02b9a\\u00b7than knew that his father was determined to put david to death.  jon\\u02b9a\\u00b7than immediately rose up from the table in the heat of anger, and he did not eat any food on the second day after the new moon, for he was upset over david and his own father had humiliated him.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ga\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"startseq yosef k\\u025b maria wo am\\u025bbi yesu k\\u025bts\\u0254 du\\u014b kabitii l\\u025b mli k\\u025bshi akrowa l\\u025b\\u014b beni betlehembii l\\u025b ew\\u0254 ak\\u025bni am\\u025bleee yi\\u014b ni herode ekp\\u025b l\\u025b hew\\u0254 beni am\\u025bk\\u025b am\\u025bhi\\u025b ts\\u0254\\u0254 wuoyigb\\u025b n\\u00ed hulu l\\u025b b\\u0254i jee y\\u025b bokagb\\u025b l\\u025b ek\\u00e3 shi fa\\u014b\\u014b ak\\u025b yosef susu shihil\\u025b ni am\\u025bk\\u025bbaakpe l\\u025b he te kapintafonyo ohiafo n\\u025b\\u025b baafee t\\u025b\\u014b\\u014b ebu eweku l\\u025b he k\\u025bj\\u025b herode k\\u025b satan he l\\u025b? ani ebaany\\u025b ekw\\u025b eweku l\\u025b daa? ani ebaany\\u025b emia ehi\\u025b etsu nitsum\\u0254 ni tsii ni yehowa ny\\u0254\\u014bm\\u0254 k\\u025bwo ed\\u025b\\u014b ak\\u025b ekw\\u025b gbek\\u025b kr\\u025bd\\u025b\\u025b n\\u025b\\u025b n\\u00ed ets\\u0254se l\\u025b l\\u025b? naagbai wuji jwere yosef hi\\u025b ni ek\\u025bbaakpe beni w\\u0254susu\\u0254 b\\u0254 ni etsu naagbai n\\u025b\\u025b ate\\u014b eko f\\u025b\\u025b eko he nii l\\u025b eha l\\u025b he l\\u025b w\\u0254baana n\\u0254 hew\\u0254 ni ehe hiaa ni ts\\u025bm\\u025bi ni y\\u0254\\u0254 \\u014bm\\u025bn\\u025b\\u2014k\\u025b w\\u0254te\\u014b m\\u0254 f\\u025b\\u025b m\\u0254\\u2014akase yosef hem\\u0254k\\u025byeli l\\u025b endseq\",\n          \"startseq ef\\u00e3 ni ema shi shi\\u014b\\u014b. endseq\",\n          \"startseq shi yonatan bi ets\\u025b saul ak\\u025b m\\u025bni hew\\u0254 esa ak\\u025b agbe l\\u025b? m\\u025bni efee?  k\\u025bk\\u025b ni saul f\\u0254\\u0303 akp\\u0254l\\u0254 koni ek\\u025btsu l\\u025b, no hew\\u0254 l\\u025b, yonatan na ak\\u025b, epapa etswa efai shi ak\\u025b ebaagbe david.  amr\\u0254 n\\u0254\\u014b\\u014b ni yonatan k\\u025b mlifu te shi y\\u025b okp\\u0254l\\u0254 l\\u025b s\\u025b\\u025b, ni eyeee niyenii ko y\\u025b gbi ni ji eny\\u0254 l\\u025b n\\u0254, ni ji ny\\u0254\\u0254\\u014b hee l\\u025b n\\u0254 jets\\u025brem\\u0254 l\\u025b, ejaak\\u025b david sane miid\\u0254 l\\u025b, ni l\\u025b di\\u025b\\u014bts\\u025b epapa eshwie ehi\\u025b shi. endseq\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into Training and Testing Sets"
      ],
      "metadata": {
        "id": "E0zxKVHkv3rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train size: {len(train_data)} | Test size: {len(test_data)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:06:51.367683Z",
          "iopub.execute_input": "2025-06-20T05:06:51.36796Z",
          "iopub.status.idle": "2025-06-20T05:06:52.131391Z",
          "shell.execute_reply.started": "2025-06-20T05:06:51.367936Z",
          "shell.execute_reply": "2025-06-20T05:06:52.130518Z"
        },
        "id": "PqtO15txv3rM",
        "outputId": "0b983ad9-128a-483a-fcf3-3943c2d435d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 9477 | Test size: 1053\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenize Sentences"
      ],
      "metadata": {
        "id": "fpS_7AEUv3rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Initialize tokenizers for both English and Ga\n",
        "eng_tokenizer = Tokenizer(filters='', oov_token='<unk>')\n",
        "ga_tokenizer = Tokenizer(filters='', oov_token='<unk>')\n",
        "\n",
        "# Fit the tokenizers on the training data\n",
        "eng_tokenizer.fit_on_texts(train_data['English'])\n",
        "ga_tokenizer.fit_on_texts(train_data['Ga'])\n",
        "\n",
        "# Convert sentences to sequences of token IDs\n",
        "train_eng_seq = eng_tokenizer.texts_to_sequences(train_data['English'])\n",
        "train_ga_seq = ga_tokenizer.texts_to_sequences(train_data['Ga'])\n",
        "\n",
        "# Calculate vocabulary sizes (used for defining model input/output dimensions)\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "ga_vocab_size = len(ga_tokenizer.word_index) + 1\n",
        "\n",
        "# Print vocabulary sizes\n",
        "print(\"English Vocabulary Size:\", eng_vocab_size)\n",
        "print(\"Ga Vocabulary Size:\", ga_vocab_size)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:06:52.132946Z",
          "iopub.execute_input": "2025-06-20T05:06:52.133398Z",
          "iopub.status.idle": "2025-06-20T05:07:11.529735Z",
          "shell.execute_reply.started": "2025-06-20T05:06:52.133373Z",
          "shell.execute_reply": "2025-06-20T05:07:11.528692Z"
        },
        "id": "HRJy2NElv3rN",
        "outputId": "e3146f0d-9110-4aca-c10a-a8b05a0c0e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocabulary Size: 20547\n",
            "Ga Vocabulary Size: 21225\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Determine Max Sequence Lengths"
      ],
      "metadata": {
        "id": "b0udRSAWv3rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the maximum sequence length for encoder (English) and decoder (Ga)\n",
        "max_encoder_len = max(len(seq) for seq in train_eng_seq)\n",
        "max_decoder_len = max(len(seq) for seq in train_ga_seq)\n",
        "\n",
        "# Print the maximum lengths\n",
        "print(\"Maximum encoder sequence length:\", max_encoder_len)\n",
        "print(\"Maximum decoder sequence length:\", max_decoder_len)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:07:11.530765Z",
          "iopub.execute_input": "2025-06-20T05:07:11.531349Z",
          "iopub.status.idle": "2025-06-20T05:07:11.53814Z",
          "shell.execute_reply.started": "2025-06-20T05:07:11.531313Z",
          "shell.execute_reply": "2025-06-20T05:07:11.537359Z"
        },
        "id": "lLIvIr3rv3rP",
        "outputId": "97b699c7-bdda-4ff9-e844-41d9240af293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum encoder sequence length: 349\n",
            "Maximum decoder sequence length: 376\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pad Sequences"
      ],
      "metadata": {
        "id": "3Svi-c_3v3rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad English sequences (encoder input)\n",
        "encoder_input_data = pad_sequences(train_eng_seq, maxlen=max_encoder_len, padding='post')\n",
        "\n",
        "# Pad Ga sequences (decoder input)\n",
        "decoder_input_data = pad_sequences(train_ga_seq, maxlen=max_decoder_len, padding='post')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:07:11.539836Z",
          "iopub.execute_input": "2025-06-20T05:07:11.540206Z",
          "iopub.status.idle": "2025-06-20T05:07:11.702455Z",
          "shell.execute_reply.started": "2025-06-20T05:07:11.540173Z",
          "shell.execute_reply": "2025-06-20T05:07:11.701198Z"
        },
        "id": "BlaSaDT2v3rP"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Decoder Target Data"
      ],
      "metadata": {
        "id": "mLz2tIgOv3rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create target data by shifting decoder input one step to the left\n",
        "decoder_target_data = np.zeros_like(decoder_input_data)\n",
        "decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n",
        "\n",
        "# Ensure the final token is the 'endseq' token\n",
        "decoder_target_data[:, -1] = ga_tokenizer.word_index.get('endseq', 0)\n",
        "\n",
        "# Expand the target data shape to match model output\n",
        "decoder_target_data = np.expand_dims(decoder_target_data, -1)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:07:11.703368Z",
          "iopub.execute_input": "2025-06-20T05:07:11.703635Z",
          "iopub.status.idle": "2025-06-20T05:07:11.717763Z",
          "shell.execute_reply.started": "2025-06-20T05:07:11.703602Z",
          "shell.execute_reply": "2025-06-20T05:07:11.716579Z"
        },
        "id": "w0x-MKxtv3rQ"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the Model Architecture"
      ],
      "metadata": {
        "id": "bXh49lCbv3rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "\n",
        "# Set hyperparameters\n",
        "embedding_dim = 256\n",
        "lstm_units = 512\n",
        "\n",
        "# ----- Encoder -----\n",
        "# Input for English sentences\n",
        "encoder_inputs = Input(shape=(max_encoder_len,))\n",
        "# Embedding layer for English input\n",
        "encoder_embedding = Embedding(input_dim=eng_vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
        "# LSTM to process the embedded input, return the hidden and cell states\n",
        "encoder_lstm, state_h, state_c = LSTM(lstm_units, return_state=True)(encoder_embedding)\n",
        "# Encoder state to pass to decoder\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# ----- Decoder -----\n",
        "# Input for Ga sentences\n",
        "decoder_inputs = Input(shape=(max_decoder_len,))\n",
        "# Embedding for target (Ga) language\n",
        "decoder_embedding = Embedding(input_dim=ga_vocab_size, output_dim=embedding_dim)(decoder_inputs)\n",
        "# LSTM that uses encoder state as its initial state\n",
        "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Final dense layer with softmax activation to predict vocabulary tokens\n",
        "decoder_dense = Dense(ga_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# ----- Final Model -----\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:07:11.718807Z",
          "iopub.execute_input": "2025-06-20T05:07:11.719146Z",
          "iopub.status.idle": "2025-06-20T05:07:12.555189Z",
          "shell.execute_reply.started": "2025-06-20T05:07:11.719093Z",
          "shell.execute_reply": "2025-06-20T05:07:12.554285Z"
        },
        "id": "73_6Cvwwv3rR"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile the Model"
      ],
      "metadata": {
        "id": "yejYgud1v3rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',  # Adaptive optimizer commonly used in NLP\n",
        "    loss='sparse_categorical_crossentropy',  # Suitable for integer-labeled sequence data\n",
        "    metrics=['accuracy']  # Track accuracy during training\n",
        ")\n",
        "\n",
        "# Print model architecture and parameter count\n",
        "model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:07:12.556267Z",
          "iopub.execute_input": "2025-06-20T05:07:12.556593Z",
          "iopub.status.idle": "2025-06-20T05:07:12.594934Z",
          "shell.execute_reply.started": "2025-06-20T05:07:12.556564Z",
          "shell.execute_reply": "2025-06-20T05:07:12.593976Z"
        },
        "id": "AMmmKT37v3rR",
        "outputId": "32add90f-508c-4763-a81c-a62f23427b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m349\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_1       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m376\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m349\u001b[0m, \u001b[38;5;34m256\u001b[0m)  ‚îÇ  \u001b[38;5;34m5,260,032\u001b[0m ‚îÇ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_1         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m376\u001b[0m, \u001b[38;5;34m256\u001b[0m)  ‚îÇ  \u001b[38;5;34m5,433,600\u001b[0m ‚îÇ input_layer_1[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm (\u001b[38;5;33mLSTM\u001b[0m)         ‚îÇ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     ‚îÇ  \u001b[38;5;34m1,574,912\u001b[0m ‚îÇ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       ‚îÇ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m376\u001b[0m,      ‚îÇ  \u001b[38;5;34m1,574,912\u001b[0m ‚îÇ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
              "‚îÇ                     ‚îÇ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       ‚îÇ\n",
              "‚îÇ                     ‚îÇ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      ‚îÇ            ‚îÇ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        ‚îÇ\n",
              "‚îÇ                     ‚îÇ \u001b[38;5;34m512\u001b[0m)]             ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m376\u001b[0m,       ‚îÇ \u001b[38;5;34m10,888,425\u001b[0m ‚îÇ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      ‚îÇ\n",
              "‚îÇ                     ‚îÇ \u001b[38;5;34m21225\u001b[0m)            ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">349</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ input_layer_1       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">376</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">349</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,260,032</span> ‚îÇ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding_1         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">376</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,433,600</span> ‚îÇ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         ‚îÇ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> ‚îÇ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îÇ                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       ‚îÇ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">376</span>,      ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> ‚îÇ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
              "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      ‚îÇ            ‚îÇ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       ‚îÇ\n",
              "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      ‚îÇ            ‚îÇ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        ‚îÇ\n",
              "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">376</span>,       ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,888,425</span> ‚îÇ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      ‚îÇ\n",
              "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">21225</span>)            ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,731,881\u001b[0m (94.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,731,881</span> (94.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,731,881\u001b[0m (94.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,731,881</span> (94.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        " Add Callbacks for Checkpoints & Early Stopping"
      ],
      "metadata": {
        "id": "gqKLpXG7v3rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n",
        "\n",
        "# Initialize WandB project\n",
        "wandb.init(project=\"english-ga-translation\", name=\"lstm-512-embed-256\")\n",
        "\n",
        "\n",
        "# Create output directory to store checkpoints and best model\n",
        "output_path = \"/content/drive/MyDrive/pretraining/\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Checkpoint path to save every epoch with epoch number\n",
        "all_epochs_path = os.path.join(output_path, \"epoch_{epoch:02d}.keras\")\n",
        "save_all = ModelCheckpoint(\n",
        "    filepath=all_epochs_path,\n",
        "    save_freq='epoch',        # Save the model after every epoch\n",
        "    save_best_only=False,     # Save every epoch regardless of performance\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Checkpoint to save only the best-performing model\n",
        "best_model_path = os.path.join(output_path, \"best_model.keras\")\n",
        "save_best = ModelCheckpoint(\n",
        "    filepath=best_model_path,\n",
        "    monitor='val_loss',       # Use validation loss to determine \"best\"\n",
        "    save_best_only=True,      # Only save the best model\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Stop training early if validation loss doesn't improve for 3 consecutive epochs\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,               # Wait 3 epochs before stopping\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Bundle all callbacks\n",
        "callbacks = [save_all, save_best, early_stop, WandbCallback()]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:07:12.595918Z",
          "iopub.execute_input": "2025-06-20T05:07:12.596233Z",
          "iopub.status.idle": "2025-06-20T05:07:12.605287Z",
          "shell.execute_reply.started": "2025-06-20T05:07:12.596211Z",
          "shell.execute_reply": "2025-06-20T05:07:12.604216Z"
        },
        "id": "Kkr2c8MAv3rS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "f7f58960-97ce-496a-84fe-d8a225206e2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lstm-512-embed-256</strong> at: <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/ckl52wgd' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/ckl52wgd</a><br> View project at: <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250622_151129-ckl52wgd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250622_151353-5usvfwno</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/5usvfwno' target=\"_blank\">lstm-512-embed-256</a></strong> to <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/5usvfwno' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/5usvfwno</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load or Create Model (Optional Resume)"
      ],
      "metadata": {
        "id": "KbKTzdvcv3rS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train One Epoch and Save"
      ],
      "metadata": {
        "id": "JVlD-78xv3rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o8AqbVJLjpi",
        "outputId": "0a838294-e5cd-4db0-9af0-c3694cd7b514"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.20.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.30.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For all Epoch"
      ],
      "metadata": {
        "id": "9SGyDfTZv3rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import tensorflow as tf\n",
        "\n",
        "# Start a new run for your translation model\n",
        "wandb.init(\n",
        "    project=\"english-ga-translation\",\n",
        "    name=\"lstm-512-embed-256\",\n",
        "    config={\n",
        "        \"embedding_dim\": 256,\n",
        "        \"lstm_units\": 512,\n",
        "        \"batch_size\": 64,\n",
        "        \"epochs\": 20,\n",
        "        \"learning_rate\": 0.01,  # Add your actual learning rate\n",
        "        \"architecture\": \"Seq2Seq-LSTM\",\n",
        "        \"dataset\": \"English-Ga-Translation\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Custom callback to manually log to WandB (like the example)\n",
        "class ManualWandbLogger(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs:\n",
        "            # Log exactly like the working example\n",
        "            wandb.log({\n",
        "                \"loss\": logs.get('loss', 0),\n",
        "                \"val_loss\": logs.get('val_loss', 0),\n",
        "                \"accuracy\": logs.get('accuracy', logs.get('acc', 0)),\n",
        "                \"val_accuracy\": logs.get('val_accuracy', logs.get('val_acc', 0)),\n",
        "                \"epoch\": epoch + 1\n",
        "            })\n",
        "            print(f\"üìä Epoch {epoch+1}/20 - Loss: {logs.get('loss', 0):.4f} - Val Loss: {logs.get('val_loss', 0):.4f}\")\n",
        "\n",
        "# Train your model\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=64,\n",
        "    epochs=20,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        save_all,\n",
        "        save_best,\n",
        "        early_stop,\n",
        "        ManualWandbLogger()  # Use manual logging like the example\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Mark the run as finished (like the example)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T05:07:12.608214Z",
          "iopub.execute_input": "2025-06-20T05:07:12.608589Z"
        },
        "id": "8HNB6rjfv3rT",
        "outputId": "4e04292c-9a5c-417b-96ce-e2cc8e3e0910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lstm-512-embed-256</strong> at: <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/5usvfwno' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/5usvfwno</a><br> View project at: <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250622_151353-5usvfwno/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250622_152024-rq7iyuk5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/rq7iyuk5' target=\"_blank\">lstm-512-embed-256</a></strong> to <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/rq7iyuk5' target=\"_blank\">https://wandb.ai/j-obodai-african-leadership-group/english-ga-translation/runs/rq7iyuk5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m 23/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m1:49:38\u001b[0m 69s/step - accuracy: 0.7449 - loss: 5.9894"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the Final Model & Tokenizers"
      ],
      "metadata": {
        "id": "r7QCyvQ9v3rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save model\n",
        "model.save(\"/content/drive/MyDrive/pretraining/english_ga_final_model.keras\")\n",
        "\n",
        "# Save tokenizers\n",
        "with open(\"/content/drive/MyDrive/pretraining/eng_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(eng_tokenizer, f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pretraining/ga_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(ga_tokenizer, f)\n",
        "\n",
        "# Save max sequence lengths\n",
        "with open(\"/content/drive/MyDrive/pretraining/max_lengths.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\"encoder_len\": max_encoder_len, \"decoder_len\": max_decoder_len}, f)\n",
        "\n",
        "print(\"‚úÖ All model components saved to /content/drive/MyDrive/pretraining/\")\n"
      ],
      "metadata": {
        "id": "kinbatstVNUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Source path from epoch 20\n",
        "src = \"/content/drive/MyDrive/pretraining/epoch_20.keras\"\n",
        "# Destination path\n",
        "dst = \"/content/drive/MyDrive/pretraining/english_ga_best_model.keras\"\n",
        "\n",
        "# Copy or rename\n",
        "shutil.copy(src, dst)\n",
        "print(\"‚úÖ Model saved as 'english_ga_best_model.keras'\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "2EOca2uCv3rT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Inference Models (Encoder + Decoder)"
      ],
      "metadata": {
        "id": "k7SsawKWv3rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load saved model\n",
        "model = load_model(\"/content/drive/MyDrive/pretraining/english_ga_final_model.keras\")\n",
        "\n",
        "# Load tokenizers\n",
        "with open(\"/content/drive/MyDrive/pretraining/eng_tokenizer.pkl\", \"rb\") as f:\n",
        "    eng_tokenizer = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pretraining/ga_tokenizer.pkl\", \"rb\") as f:\n",
        "    ga_tokenizer = pickle.load(f)\n",
        "\n",
        "# Load max lengths\n",
        "with open(\"/content/drive/MyDrive/pretraining/max_lengths.pkl\", \"rb\") as f:\n",
        "    max_lengths = pickle.load(f)\n",
        "\n",
        "max_encoder_len = max_lengths[\"encoder_len\"]\n",
        "max_decoder_len = max_lengths[\"decoder_len\"]\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ytAxnxDOv3rU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Translate Function"
      ],
      "metadata": {
        "id": "fDDPTcvNv3rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_input(input_text):\n",
        "    input_seq = eng_tokenizer.texts_to_sequences([input_text.lower()])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_encoder_len, padding='post')\n",
        "\n",
        "    start_token = ga_tokenizer.word_index.get('startseq', 1)\n",
        "    end_token = ga_tokenizer.word_index.get('endseq', 2)\n",
        "\n",
        "    target_seq = np.zeros((1, max_decoder_len))\n",
        "    target_seq[0, 0] = start_token\n",
        "\n",
        "    translated_sentence = []\n",
        "\n",
        "    for i in range(1, max_decoder_len):\n",
        "        predictions = model.predict([input_seq, target_seq], verbose=0)\n",
        "        predicted_id = np.argmax(predictions[0, i, :])\n",
        "        predicted_word = ga_tokenizer.index_word.get(predicted_id, '<unk>')\n",
        "\n",
        "        if predicted_word in ['endseq', '<pad>']:\n",
        "            break\n",
        "\n",
        "        translated_sentence.append(predicted_word)\n",
        "        target_seq[0, i] = predicted_id\n",
        "\n",
        "    return ' '.join(translated_sentence)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Mj14Z0T4v3rU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try Sample Translations"
      ],
      "metadata": {
        "id": "CwR_8uV6v3rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"Enter English (or 'exit'): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    result = translate_input(user_input)\n",
        "    print(\"Ga Translation:\", result)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Vq23fDiHv3rU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/pretraining/eng_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(eng_tokenizer, f)\n"
      ],
      "metadata": {
        "id": "lM43KZ7AoPfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pretraining/eng_tokenizer.pkl\", \"rb\") as f:\n",
        "    eng_tokenizer = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pretraining/ga_tokenizer.pkl\", \"rb\") as f:\n",
        "    ga_tokenizer = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pretraining/max_lengths.pkl\", \"rb\") as f:\n",
        "    max_lengths = pickle.load(f)\n",
        "\n",
        "max_encoder_len = max_lengths[\"encoder_len\"]\n",
        "max_decoder_len = max_lengths[\"decoder_len\"]\n"
      ],
      "metadata": {
        "id": "3LOm81XKoYYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get input from user\n",
        "input_text = input(\"Enter English: \").strip().lower()\n",
        "\n",
        "# Tokenize and pad\n",
        "input_seq = eng_tokenizer.texts_to_sequences([input_text])\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_encoder_len, padding='post')\n"
      ],
      "metadata": {
        "id": "MHtwr8UAokod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Encoded input sequence:\", input_seq)\n"
      ],
      "metadata": {
        "id": "40cweZoPosYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Create empty target sequence with just the start token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = ga_tokenizer.word_index['startseq']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = ga_tokenizer.index_word.get(sampled_token_index, '<unk>')\n",
        "\n",
        "        if sampled_word == 'endseq' or len(decoded_sentence) > max_decoder_len:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence.append(sampled_word)\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(decoded_sentence)\n"
      ],
      "metadata": {
        "id": "7QN980j0oxDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_sequence(pad_sequences(\n",
        "    eng_tokenizer.texts_to_sequences([\"how are you?\"]),\n",
        "    maxlen=max_encoder_len, padding='post')))\n"
      ],
      "metadata": {
        "id": "bpwzznO7o2AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"/content/drive/MyDrive/pretraining/english_ga_best_model.keras\")\n",
        "\n",
        "# Load tokenizers\n",
        "with open(\"/content/drive/MyDrive/pretraining/eng_tokenizer.pkl\", \"rb\") as f:\n",
        "    eng_tokenizer = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pretraining/ga_tokenizer.pkl\", \"rb\") as f:\n",
        "    ga_tokenizer = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pretraining/max_lengths.pkl\", \"rb\") as f:\n",
        "    max_lengths = pickle.load(f)\n",
        "\n",
        "max_encoder_len = max_lengths['encoder_len']\n",
        "max_decoder_len = max_lengths['decoder_len']\n",
        "\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "ga_vocab_size = len(ga_tokenizer.word_index) + 1\n"
      ],
      "metadata": {
        "id": "Loj13wlLqvDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "\n",
        "# Get layers from the trained model\n",
        "encoder_inputs = model.input[0]\n",
        "decoder_inputs = model.input[1]\n",
        "decoder_outputs = model.output\n",
        "\n",
        "# Extract the layers we need\n",
        "encoder_embedding_layer = model.get_layer('embedding')\n",
        "decoder_embedding_layer = model.get_layer('embedding_1')\n",
        "encoder_lstm_layer = model.get_layer('lstm')\n",
        "decoder_lstm_layer = model.get_layer('lstm_1')\n",
        "decoder_dense = model.get_layer('dense')\n",
        "\n",
        "# Encoder model\n",
        "encoder_embedded = encoder_embedding_layer(encoder_inputs)\n",
        "_, state_h_enc, state_c_enc = encoder_lstm_layer(encoder_embedded)\n",
        "encoder_model = Model(encoder_inputs, [state_h_enc, state_c_enc])\n",
        "\n",
        "# Decoder model\n",
        "decoder_state_input_h = Input(shape=(512,))\n",
        "decoder_state_input_c = Input(shape=(512,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_embedded = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm_layer(\n",
        "    decoder_embedded, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n"
      ],
      "metadata": {
        "id": "mhq0MYHGq54k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input sentence\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Start with \"startseq\"\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = ga_tokenizer.word_index.get('startseq', 1)\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = ga_tokenizer.index_word.get(sampled_token_index, '<unk>')\n",
        "\n",
        "        if sampled_word == 'endseq' or len(decoded_sentence) > max_decoder_len:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence.append(sampled_word)\n",
        "\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(decoded_sentence)\n"
      ],
      "metadata": {
        "id": "GnYU-BgqrAVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"God\"\n",
        "input_seq = eng_tokenizer.texts_to_sequences([test_sentence.lower()])\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_encoder_len, padding='post')\n",
        "\n",
        "translation = decode_sequence(input_seq)\n",
        "print(f\"Ga Translation: {translation}\")\n"
      ],
      "metadata": {
        "id": "EAZjvqk4rEGi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}